{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5ad1d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph=\"In today's rapidly evolving world, programming has emerged as a fundamental skill that underpins innovation, drives progress, and shapes the future of technology. From developing sophisticated software applications to designing cutting-edge algorithms, programming serves as the cornerstone of digital transformation across industries. With its ability to translate ideas into executable code, programming empowers individuals to create solutions to complex problems, automate tedious tasks, and unlock new opportunities for growth and efficiency. Moreover, programming fosters critical thinking, problem-solving, and computational thinking skills, equipping individuals with the ability to analyze data, derive insights, and make informed decisions. As technology continues to advance, programming languages evolve and new paradigms emerge, offering endless possibilities for exploration and experimentation. By mastering programming, individuals not only gain access to lucrative career opportunities but also become agents of change, driving innovation and shaping the future of society. Whether it's developing artificial intelligence algorithms, building virtual reality experiences, or creating interactive websites, programming enables individuals to unleash their creativity, express their ideas, and make a meaningful impact on the world. In essence, programming is more than just a technical skill. it's a gateway to endless possibilities, a catalyst for innovation, and a driving force behind the digital revolution.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27a4ec7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d63e947",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer =Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f8034060",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([paragraph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4cbc9e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'and',\n",
       " 2: 'to',\n",
       " 3: 'programming',\n",
       " 4: 'a',\n",
       " 5: 'the',\n",
       " 6: 'of',\n",
       " 7: 'individuals',\n",
       " 8: 'as',\n",
       " 9: 'innovation',\n",
       " 10: 'for',\n",
       " 11: 'in',\n",
       " 12: 'world',\n",
       " 13: 'skill',\n",
       " 14: 'future',\n",
       " 15: 'technology',\n",
       " 16: 'developing',\n",
       " 17: 'algorithms',\n",
       " 18: 'digital',\n",
       " 19: 'with',\n",
       " 20: 'ability',\n",
       " 21: 'ideas',\n",
       " 22: 'new',\n",
       " 23: 'opportunities',\n",
       " 24: 'thinking',\n",
       " 25: 'make',\n",
       " 26: 'endless',\n",
       " 27: 'possibilities',\n",
       " 28: 'driving',\n",
       " 29: \"it's\",\n",
       " 30: 'their',\n",
       " 31: \"today's\",\n",
       " 32: 'rapidly',\n",
       " 33: 'evolving',\n",
       " 34: 'has',\n",
       " 35: 'emerged',\n",
       " 36: 'fundamental',\n",
       " 37: 'that',\n",
       " 38: 'underpins',\n",
       " 39: 'drives',\n",
       " 40: 'progress',\n",
       " 41: 'shapes',\n",
       " 42: 'from',\n",
       " 43: 'sophisticated',\n",
       " 44: 'software',\n",
       " 45: 'applications',\n",
       " 46: 'designing',\n",
       " 47: 'cutting',\n",
       " 48: 'edge',\n",
       " 49: 'serves',\n",
       " 50: 'cornerstone',\n",
       " 51: 'transformation',\n",
       " 52: 'across',\n",
       " 53: 'industries',\n",
       " 54: 'its',\n",
       " 55: 'translate',\n",
       " 56: 'into',\n",
       " 57: 'executable',\n",
       " 58: 'code',\n",
       " 59: 'empowers',\n",
       " 60: 'create',\n",
       " 61: 'solutions',\n",
       " 62: 'complex',\n",
       " 63: 'problems',\n",
       " 64: 'automate',\n",
       " 65: 'tedious',\n",
       " 66: 'tasks',\n",
       " 67: 'unlock',\n",
       " 68: 'growth',\n",
       " 69: 'efficiency',\n",
       " 70: 'moreover',\n",
       " 71: 'fosters',\n",
       " 72: 'critical',\n",
       " 73: 'problem',\n",
       " 74: 'solving',\n",
       " 75: 'computational',\n",
       " 76: 'skills',\n",
       " 77: 'equipping',\n",
       " 78: 'analyze',\n",
       " 79: 'data',\n",
       " 80: 'derive',\n",
       " 81: 'insights',\n",
       " 82: 'informed',\n",
       " 83: 'decisions',\n",
       " 84: 'continues',\n",
       " 85: 'advance',\n",
       " 86: 'languages',\n",
       " 87: 'evolve',\n",
       " 88: 'paradigms',\n",
       " 89: 'emerge',\n",
       " 90: 'offering',\n",
       " 91: 'exploration',\n",
       " 92: 'experimentation',\n",
       " 93: 'by',\n",
       " 94: 'mastering',\n",
       " 95: 'not',\n",
       " 96: 'only',\n",
       " 97: 'gain',\n",
       " 98: 'access',\n",
       " 99: 'lucrative',\n",
       " 100: 'career',\n",
       " 101: 'but',\n",
       " 102: 'also',\n",
       " 103: 'become',\n",
       " 104: 'agents',\n",
       " 105: 'change',\n",
       " 106: 'shaping',\n",
       " 107: 'society',\n",
       " 108: 'whether',\n",
       " 109: 'artificial',\n",
       " 110: 'intelligence',\n",
       " 111: 'building',\n",
       " 112: 'virtual',\n",
       " 113: 'reality',\n",
       " 114: 'experiences',\n",
       " 115: 'or',\n",
       " 116: 'creating',\n",
       " 117: 'interactive',\n",
       " 118: 'websites',\n",
       " 119: 'enables',\n",
       " 120: 'unleash',\n",
       " 121: 'creativity',\n",
       " 122: 'express',\n",
       " 123: 'meaningful',\n",
       " 124: 'impact',\n",
       " 125: 'on',\n",
       " 126: 'essence',\n",
       " 127: 'is',\n",
       " 128: 'more',\n",
       " 129: 'than',\n",
       " 130: 'just',\n",
       " 131: 'technical',\n",
       " 132: 'gateway',\n",
       " 133: 'catalyst',\n",
       " 134: 'force',\n",
       " 135: 'behind',\n",
       " 136: 'revolution'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "512d34a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11, 31], [11, 31, 32], [11, 31, 32, 33], [11, 31, 32, 33, 12], [11, 31, 32, 33, 12, 3], [11, 31, 32, 33, 12, 3, 34], [11, 31, 32, 33, 12, 3, 34, 35], [11, 31, 32, 33, 12, 3, 34, 35, 8], [11, 31, 32, 33, 12, 3, 34, 35, 8, 4], [11, 31, 32, 33, 12, 3, 34, 35, 8, 4, 36], [11, 31, 32, 33, 12, 3, 34, 35, 8, 4, 36, 13], [11, 31, 32, 33, 12, 3, 34, 35, 8, 4, 36, 13, 37], [11, 31, 32, 33, 12, 3, 34, 35, 8, 4, 36, 13, 37, 38], [11, 31, 32, 33, 12, 3, 34, 35, 8, 4, 36, 13, 37, 38, 9], [11, 31, 32, 33, 12, 3, 34, 35, 8, 4, 36, 13, 37, 38, 9, 39], [11, 31, 32, 33, 12, 3, 34, 35, 8, 4, 36, 13, 37, 38, 9, 39, 40], [11, 31, 32, 33, 12, 3, 34, 35, 8, 4, 36, 13, 37, 38, 9, 39, 40, 1], [11, 31, 32, 33, 12, 3, 34, 35, 8, 4, 36, 13, 37, 38, 9, 39, 40, 1, 41], [11, 31, 32, 33, 12, 3, 34, 35, 8, 4, 36, 13, 37, 38, 9, 39, 40, 1, 41, 5], [11, 31, 32, 33, 12, 3, 34, 35, 8, 4, 36, 13, 37, 38, 9, 39, 40, 1, 41, 5, 14], [11, 31, 32, 33, 12, 3, 34, 35, 8, 4, 36, 13, 37, 38, 9, 39, 40, 1, 41, 5, 14, 6], [11, 31, 32, 33, 12, 3, 34, 35, 8, 4, 36, 13, 37, 38, 9, 39, 40, 1, 41, 5, 14, 6, 15], [42, 16], [42, 16, 43], [42, 16, 43, 44], [42, 16, 43, 44, 45], [42, 16, 43, 44, 45, 2], [42, 16, 43, 44, 45, 2, 46], [42, 16, 43, 44, 45, 2, 46, 47], [42, 16, 43, 44, 45, 2, 46, 47, 48], [42, 16, 43, 44, 45, 2, 46, 47, 48, 17], [42, 16, 43, 44, 45, 2, 46, 47, 48, 17, 3], [42, 16, 43, 44, 45, 2, 46, 47, 48, 17, 3, 49], [42, 16, 43, 44, 45, 2, 46, 47, 48, 17, 3, 49, 8], [42, 16, 43, 44, 45, 2, 46, 47, 48, 17, 3, 49, 8, 5], [42, 16, 43, 44, 45, 2, 46, 47, 48, 17, 3, 49, 8, 5, 50], [42, 16, 43, 44, 45, 2, 46, 47, 48, 17, 3, 49, 8, 5, 50, 6], [42, 16, 43, 44, 45, 2, 46, 47, 48, 17, 3, 49, 8, 5, 50, 6, 18], [42, 16, 43, 44, 45, 2, 46, 47, 48, 17, 3, 49, 8, 5, 50, 6, 18, 51], [42, 16, 43, 44, 45, 2, 46, 47, 48, 17, 3, 49, 8, 5, 50, 6, 18, 51, 52], [42, 16, 43, 44, 45, 2, 46, 47, 48, 17, 3, 49, 8, 5, 50, 6, 18, 51, 52, 53], [19, 54], [19, 54, 20], [19, 54, 20, 2], [19, 54, 20, 2, 55], [19, 54, 20, 2, 55, 21], [19, 54, 20, 2, 55, 21, 56], [19, 54, 20, 2, 55, 21, 56, 57], [19, 54, 20, 2, 55, 21, 56, 57, 58], [19, 54, 20, 2, 55, 21, 56, 57, 58, 3], [19, 54, 20, 2, 55, 21, 56, 57, 58, 3, 59], [19, 54, 20, 2, 55, 21, 56, 57, 58, 3, 59, 7], [19, 54, 20, 2, 55, 21, 56, 57, 58, 3, 59, 7, 2], [19, 54, 20, 2, 55, 21, 56, 57, 58, 3, 59, 7, 2, 60], [19, 54, 20, 2, 55, 21, 56, 57, 58, 3, 59, 7, 2, 60, 61], [19, 54, 20, 2, 55, 21, 56, 57, 58, 3, 59, 7, 2, 60, 61, 2], [19, 54, 20, 2, 55, 21, 56, 57, 58, 3, 59, 7, 2, 60, 61, 2, 62], [19, 54, 20, 2, 55, 21, 56, 57, 58, 3, 59, 7, 2, 60, 61, 2, 62, 63], [19, 54, 20, 2, 55, 21, 56, 57, 58, 3, 59, 7, 2, 60, 61, 2, 62, 63, 64], [19, 54, 20, 2, 55, 21, 56, 57, 58, 3, 59, 7, 2, 60, 61, 2, 62, 63, 64, 65], [19, 54, 20, 2, 55, 21, 56, 57, 58, 3, 59, 7, 2, 60, 61, 2, 62, 63, 64, 65, 66], [19, 54, 20, 2, 55, 21, 56, 57, 58, 3, 59, 7, 2, 60, 61, 2, 62, 63, 64, 65, 66, 1], [19, 54, 20, 2, 55, 21, 56, 57, 58, 3, 59, 7, 2, 60, 61, 2, 62, 63, 64, 65, 66, 1, 67], [19, 54, 20, 2, 55, 21, 56, 57, 58, 3, 59, 7, 2, 60, 61, 2, 62, 63, 64, 65, 66, 1, 67, 22], [19, 54, 20, 2, 55, 21, 56, 57, 58, 3, 59, 7, 2, 60, 61, 2, 62, 63, 64, 65, 66, 1, 67, 22, 23], [19, 54, 20, 2, 55, 21, 56, 57, 58, 3, 59, 7, 2, 60, 61, 2, 62, 63, 64, 65, 66, 1, 67, 22, 23, 10], [19, 54, 20, 2, 55, 21, 56, 57, 58, 3, 59, 7, 2, 60, 61, 2, 62, 63, 64, 65, 66, 1, 67, 22, 23, 10, 68], [19, 54, 20, 2, 55, 21, 56, 57, 58, 3, 59, 7, 2, 60, 61, 2, 62, 63, 64, 65, 66, 1, 67, 22, 23, 10, 68, 1], [19, 54, 20, 2, 55, 21, 56, 57, 58, 3, 59, 7, 2, 60, 61, 2, 62, 63, 64, 65, 66, 1, 67, 22, 23, 10, 68, 1, 69], [70, 3], [70, 3, 71], [70, 3, 71, 72], [70, 3, 71, 72, 24], [70, 3, 71, 72, 24, 73], [70, 3, 71, 72, 24, 73, 74], [70, 3, 71, 72, 24, 73, 74, 1], [70, 3, 71, 72, 24, 73, 74, 1, 75], [70, 3, 71, 72, 24, 73, 74, 1, 75, 24], [70, 3, 71, 72, 24, 73, 74, 1, 75, 24, 76], [70, 3, 71, 72, 24, 73, 74, 1, 75, 24, 76, 77], [70, 3, 71, 72, 24, 73, 74, 1, 75, 24, 76, 77, 7], [70, 3, 71, 72, 24, 73, 74, 1, 75, 24, 76, 77, 7, 19], [70, 3, 71, 72, 24, 73, 74, 1, 75, 24, 76, 77, 7, 19, 5], [70, 3, 71, 72, 24, 73, 74, 1, 75, 24, 76, 77, 7, 19, 5, 20], [70, 3, 71, 72, 24, 73, 74, 1, 75, 24, 76, 77, 7, 19, 5, 20, 2], [70, 3, 71, 72, 24, 73, 74, 1, 75, 24, 76, 77, 7, 19, 5, 20, 2, 78], [70, 3, 71, 72, 24, 73, 74, 1, 75, 24, 76, 77, 7, 19, 5, 20, 2, 78, 79], [70, 3, 71, 72, 24, 73, 74, 1, 75, 24, 76, 77, 7, 19, 5, 20, 2, 78, 79, 80], [70, 3, 71, 72, 24, 73, 74, 1, 75, 24, 76, 77, 7, 19, 5, 20, 2, 78, 79, 80, 81], [70, 3, 71, 72, 24, 73, 74, 1, 75, 24, 76, 77, 7, 19, 5, 20, 2, 78, 79, 80, 81, 1], [70, 3, 71, 72, 24, 73, 74, 1, 75, 24, 76, 77, 7, 19, 5, 20, 2, 78, 79, 80, 81, 1, 25], [70, 3, 71, 72, 24, 73, 74, 1, 75, 24, 76, 77, 7, 19, 5, 20, 2, 78, 79, 80, 81, 1, 25, 82], [70, 3, 71, 72, 24, 73, 74, 1, 75, 24, 76, 77, 7, 19, 5, 20, 2, 78, 79, 80, 81, 1, 25, 82, 83], [8, 15], [8, 15, 84], [8, 15, 84, 2], [8, 15, 84, 2, 85], [8, 15, 84, 2, 85, 3], [8, 15, 84, 2, 85, 3, 86], [8, 15, 84, 2, 85, 3, 86, 87], [8, 15, 84, 2, 85, 3, 86, 87, 1], [8, 15, 84, 2, 85, 3, 86, 87, 1, 22], [8, 15, 84, 2, 85, 3, 86, 87, 1, 22, 88], [8, 15, 84, 2, 85, 3, 86, 87, 1, 22, 88, 89], [8, 15, 84, 2, 85, 3, 86, 87, 1, 22, 88, 89, 90], [8, 15, 84, 2, 85, 3, 86, 87, 1, 22, 88, 89, 90, 26], [8, 15, 84, 2, 85, 3, 86, 87, 1, 22, 88, 89, 90, 26, 27], [8, 15, 84, 2, 85, 3, 86, 87, 1, 22, 88, 89, 90, 26, 27, 10], [8, 15, 84, 2, 85, 3, 86, 87, 1, 22, 88, 89, 90, 26, 27, 10, 91], [8, 15, 84, 2, 85, 3, 86, 87, 1, 22, 88, 89, 90, 26, 27, 10, 91, 1], [8, 15, 84, 2, 85, 3, 86, 87, 1, 22, 88, 89, 90, 26, 27, 10, 91, 1, 92], [93, 94], [93, 94, 3], [93, 94, 3, 7], [93, 94, 3, 7, 95], [93, 94, 3, 7, 95, 96], [93, 94, 3, 7, 95, 96, 97], [93, 94, 3, 7, 95, 96, 97, 98], [93, 94, 3, 7, 95, 96, 97, 98, 2], [93, 94, 3, 7, 95, 96, 97, 98, 2, 99], [93, 94, 3, 7, 95, 96, 97, 98, 2, 99, 100], [93, 94, 3, 7, 95, 96, 97, 98, 2, 99, 100, 23], [93, 94, 3, 7, 95, 96, 97, 98, 2, 99, 100, 23, 101], [93, 94, 3, 7, 95, 96, 97, 98, 2, 99, 100, 23, 101, 102], [93, 94, 3, 7, 95, 96, 97, 98, 2, 99, 100, 23, 101, 102, 103], [93, 94, 3, 7, 95, 96, 97, 98, 2, 99, 100, 23, 101, 102, 103, 104], [93, 94, 3, 7, 95, 96, 97, 98, 2, 99, 100, 23, 101, 102, 103, 104, 6], [93, 94, 3, 7, 95, 96, 97, 98, 2, 99, 100, 23, 101, 102, 103, 104, 6, 105], [93, 94, 3, 7, 95, 96, 97, 98, 2, 99, 100, 23, 101, 102, 103, 104, 6, 105, 28], [93, 94, 3, 7, 95, 96, 97, 98, 2, 99, 100, 23, 101, 102, 103, 104, 6, 105, 28, 9], [93, 94, 3, 7, 95, 96, 97, 98, 2, 99, 100, 23, 101, 102, 103, 104, 6, 105, 28, 9, 1], [93, 94, 3, 7, 95, 96, 97, 98, 2, 99, 100, 23, 101, 102, 103, 104, 6, 105, 28, 9, 1, 106], [93, 94, 3, 7, 95, 96, 97, 98, 2, 99, 100, 23, 101, 102, 103, 104, 6, 105, 28, 9, 1, 106, 5], [93, 94, 3, 7, 95, 96, 97, 98, 2, 99, 100, 23, 101, 102, 103, 104, 6, 105, 28, 9, 1, 106, 5, 14], [93, 94, 3, 7, 95, 96, 97, 98, 2, 99, 100, 23, 101, 102, 103, 104, 6, 105, 28, 9, 1, 106, 5, 14, 6], [93, 94, 3, 7, 95, 96, 97, 98, 2, 99, 100, 23, 101, 102, 103, 104, 6, 105, 28, 9, 1, 106, 5, 14, 6, 107], [108, 29], [108, 29, 16], [108, 29, 16, 109], [108, 29, 16, 109, 110], [108, 29, 16, 109, 110, 17], [108, 29, 16, 109, 110, 17, 111], [108, 29, 16, 109, 110, 17, 111, 112], [108, 29, 16, 109, 110, 17, 111, 112, 113], [108, 29, 16, 109, 110, 17, 111, 112, 113, 114], [108, 29, 16, 109, 110, 17, 111, 112, 113, 114, 115], [108, 29, 16, 109, 110, 17, 111, 112, 113, 114, 115, 116], [108, 29, 16, 109, 110, 17, 111, 112, 113, 114, 115, 116, 117], [108, 29, 16, 109, 110, 17, 111, 112, 113, 114, 115, 116, 117, 118], [108, 29, 16, 109, 110, 17, 111, 112, 113, 114, 115, 116, 117, 118, 3], [108, 29, 16, 109, 110, 17, 111, 112, 113, 114, 115, 116, 117, 118, 3, 119], [108, 29, 16, 109, 110, 17, 111, 112, 113, 114, 115, 116, 117, 118, 3, 119, 7], [108, 29, 16, 109, 110, 17, 111, 112, 113, 114, 115, 116, 117, 118, 3, 119, 7, 2], [108, 29, 16, 109, 110, 17, 111, 112, 113, 114, 115, 116, 117, 118, 3, 119, 7, 2, 120], [108, 29, 16, 109, 110, 17, 111, 112, 113, 114, 115, 116, 117, 118, 3, 119, 7, 2, 120, 30], [108, 29, 16, 109, 110, 17, 111, 112, 113, 114, 115, 116, 117, 118, 3, 119, 7, 2, 120, 30, 121], [108, 29, 16, 109, 110, 17, 111, 112, 113, 114, 115, 116, 117, 118, 3, 119, 7, 2, 120, 30, 121, 122], [108, 29, 16, 109, 110, 17, 111, 112, 113, 114, 115, 116, 117, 118, 3, 119, 7, 2, 120, 30, 121, 122, 30], [108, 29, 16, 109, 110, 17, 111, 112, 113, 114, 115, 116, 117, 118, 3, 119, 7, 2, 120, 30, 121, 122, 30, 21], [108, 29, 16, 109, 110, 17, 111, 112, 113, 114, 115, 116, 117, 118, 3, 119, 7, 2, 120, 30, 121, 122, 30, 21, 1], [108, 29, 16, 109, 110, 17, 111, 112, 113, 114, 115, 116, 117, 118, 3, 119, 7, 2, 120, 30, 121, 122, 30, 21, 1, 25], [108, 29, 16, 109, 110, 17, 111, 112, 113, 114, 115, 116, 117, 118, 3, 119, 7, 2, 120, 30, 121, 122, 30, 21, 1, 25, 4], [108, 29, 16, 109, 110, 17, 111, 112, 113, 114, 115, 116, 117, 118, 3, 119, 7, 2, 120, 30, 121, 122, 30, 21, 1, 25, 4, 123], [108, 29, 16, 109, 110, 17, 111, 112, 113, 114, 115, 116, 117, 118, 3, 119, 7, 2, 120, 30, 121, 122, 30, 21, 1, 25, 4, 123, 124], [108, 29, 16, 109, 110, 17, 111, 112, 113, 114, 115, 116, 117, 118, 3, 119, 7, 2, 120, 30, 121, 122, 30, 21, 1, 25, 4, 123, 124, 125], [108, 29, 16, 109, 110, 17, 111, 112, 113, 114, 115, 116, 117, 118, 3, 119, 7, 2, 120, 30, 121, 122, 30, 21, 1, 25, 4, 123, 124, 125, 5], [108, 29, 16, 109, 110, 17, 111, 112, 113, 114, 115, 116, 117, 118, 3, 119, 7, 2, 120, 30, 121, 122, 30, 21, 1, 25, 4, 123, 124, 125, 5, 12], [11, 126], [11, 126, 3], [11, 126, 3, 127], [11, 126, 3, 127, 128], [11, 126, 3, 127, 128, 129], [11, 126, 3, 127, 128, 129, 130], [11, 126, 3, 127, 128, 129, 130, 4], [11, 126, 3, 127, 128, 129, 130, 4, 131], [11, 126, 3, 127, 128, 129, 130, 4, 131, 13], [29, 4], [29, 4, 132], [29, 4, 132, 2], [29, 4, 132, 2, 26], [29, 4, 132, 2, 26, 27], [29, 4, 132, 2, 26, 27, 4], [29, 4, 132, 2, 26, 27, 4, 133], [29, 4, 132, 2, 26, 27, 4, 133, 10], [29, 4, 132, 2, 26, 27, 4, 133, 10, 9], [29, 4, 132, 2, 26, 27, 4, 133, 10, 9, 1], [29, 4, 132, 2, 26, 27, 4, 133, 10, 9, 1, 4], [29, 4, 132, 2, 26, 27, 4, 133, 10, 9, 1, 4, 28], [29, 4, 132, 2, 26, 27, 4, 133, 10, 9, 1, 4, 28, 134], [29, 4, 132, 2, 26, 27, 4, 133, 10, 9, 1, 4, 28, 134, 135], [29, 4, 132, 2, 26, 27, 4, 133, 10, 9, 1, 4, 28, 134, 135, 5], [29, 4, 132, 2, 26, 27, 4, 133, 10, 9, 1, 4, 28, 134, 135, 5, 18], [29, 4, 132, 2, 26, 27, 4, 133, 10, 9, 1, 4, 28, 134, 135, 5, 18, 136]]\n"
     ]
    }
   ],
   "source": [
    "input_sequence=[]\n",
    "for sentence in paragraph.split('.'):\n",
    "    tokenized_setences=tokenizer.texts_to_sequences([sentence])[0]\n",
    "#     print(tokenized_setences)\n",
    "#     print(len(tokenized_setences))\n",
    "  \n",
    "    for i in range(1,len(tokenized_setences)):\n",
    "        input_sequence.append(tokenized_setences[:i+1])\n",
    "\n",
    "    \n",
    "print(input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "84a522cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1e19501e",
   "metadata": {},
   "outputs": [],
   "source": [
    " list=[] \n",
    "for x in input_sequence:\n",
    "    list.append(len(x))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dfaf81ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length=max(list)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2b0b7f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_sequences=pad_sequences(input_sequence , maxlen =max_length , padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c3b90f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2d2459d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 31)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = padded_sequences[:,:-1]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2d5dd068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=padded_sequences[:,-1]\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aed48844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Assuming Y contains class labels as integers\n",
    "# Y = [0, 1, 2, 1, 0, ...]\n",
    "\n",
    "# Convert class labels to one-hot encoded vectors\n",
    "Y = to_categorical(Y, num_classes=137)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ab5af036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 137)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dc6a3818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM,Embedding,Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b6745c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model =Sequential()\n",
    "model.add(Embedding(137 , 100 ,input_length=31))\n",
    "model.add(LSTM(125))\n",
    "model.add(Dense(137 , activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8787133b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fd1c175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 31, 100)           13700     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 125)               113000    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 137)               17262     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 143962 (562.35 KB)\n",
      "Trainable params: 143962 (562.35 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "75088ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "7/7 [==============================] - 3s 25ms/step - loss: 4.9190 - accuracy: 0.0363\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 4.8885 - accuracy: 0.0674\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 4.8052 - accuracy: 0.0415\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 4.7596 - accuracy: 0.0363\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 4.7062 - accuracy: 0.0466\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 4.6757 - accuracy: 0.0518\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 4.6616 - accuracy: 0.0518\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 4.6380 - accuracy: 0.0570\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 4.6083 - accuracy: 0.0829\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 4.5688 - accuracy: 0.0777\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 4.5466 - accuracy: 0.0674\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 4.4885 - accuracy: 0.0777\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 4.4435 - accuracy: 0.0777\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 4.3859 - accuracy: 0.0777\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 4.3562 - accuracy: 0.0777\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 4.3152 - accuracy: 0.0933\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 4.3310 - accuracy: 0.0777\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 4.2283 - accuracy: 0.0933\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 4.1902 - accuracy: 0.0933\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 4.1554 - accuracy: 0.0777\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 4.1211 - accuracy: 0.0933\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 4.0820 - accuracy: 0.0829\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 4.0636 - accuracy: 0.0881\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 4.0264 - accuracy: 0.0933\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 3.9665 - accuracy: 0.0933\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 3.9144 - accuracy: 0.0984\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 3.9641 - accuracy: 0.0933\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 3.8325 - accuracy: 0.0829\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 3.7669 - accuracy: 0.0933\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 3.7063 - accuracy: 0.0984\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 3.6309 - accuracy: 0.1295\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 3.5379 - accuracy: 0.1554\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 3.5542 - accuracy: 0.1658\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 3.4643 - accuracy: 0.1606\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 3.3576 - accuracy: 0.1917\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 3.2638 - accuracy: 0.1865\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 3.1746 - accuracy: 0.2073\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 3.1346 - accuracy: 0.2073\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 3.1267 - accuracy: 0.1969\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 3.0468 - accuracy: 0.2021\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.9415 - accuracy: 0.2487\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.8959 - accuracy: 0.2073\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.8112 - accuracy: 0.2694\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.7786 - accuracy: 0.2591\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.7060 - accuracy: 0.2591\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.6456 - accuracy: 0.2746\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.5424 - accuracy: 0.3005\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.4779 - accuracy: 0.3368\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.4822 - accuracy: 0.3316\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.3870 - accuracy: 0.3368\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.3129 - accuracy: 0.3212\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 2.2291 - accuracy: 0.3679\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 2.2846 - accuracy: 0.3420\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2129 - accuracy: 0.3834\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.1598 - accuracy: 0.4456\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.1285 - accuracy: 0.3990\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.0706 - accuracy: 0.4611\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.0074 - accuracy: 0.4870\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.9811 - accuracy: 0.4560\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.9359 - accuracy: 0.4767\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.8692 - accuracy: 0.4870\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.8340 - accuracy: 0.5078\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.8100 - accuracy: 0.5285\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.7592 - accuracy: 0.5907\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.7289 - accuracy: 0.5699\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.6945 - accuracy: 0.5648\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.6633 - accuracy: 0.5803\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.6287 - accuracy: 0.5907\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.6127 - accuracy: 0.6114\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.5849 - accuracy: 0.6218\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.5810 - accuracy: 0.5907\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.5560 - accuracy: 0.6477\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.5147 - accuracy: 0.6788\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.4788 - accuracy: 0.6839\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.4678 - accuracy: 0.6839\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.4277 - accuracy: 0.7254\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.3968 - accuracy: 0.6995\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.3558 - accuracy: 0.7047\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 22ms/step - loss: 1.3334 - accuracy: 0.6995\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.3135 - accuracy: 0.7150\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.2707 - accuracy: 0.7565\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.2449 - accuracy: 0.7617\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.2386 - accuracy: 0.7617\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.2028 - accuracy: 0.7772\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.1797 - accuracy: 0.7824\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.1531 - accuracy: 0.8031\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.1430 - accuracy: 0.7979\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.1280 - accuracy: 0.7979\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.1157 - accuracy: 0.7927\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.0885 - accuracy: 0.7979\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.0927 - accuracy: 0.7979\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.0640 - accuracy: 0.8187\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.0384 - accuracy: 0.8187\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.0119 - accuracy: 0.8290\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.0947 - accuracy: 0.7927\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.1045 - accuracy: 0.8083\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.0784 - accuracy: 0.8031\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.0367 - accuracy: 0.8290\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.9958 - accuracy: 0.8342\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.0061 - accuracy: 0.8083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x271b3e608e0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "25d2eb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "fosters\n"
     ]
    }
   ],
   "source": [
    "text=\"programming\"\n",
    "\n",
    "tokenized_text=tokenizer.texts_to_sequences([text])[0]\n",
    "padded_text=pad_sequences([tokenized_text] , maxlen=31 , padding=\"pre\")\n",
    "pos = np.argmax(model.predict(padded_text))\n",
    "\n",
    "for index,word in tokenizer.index_word.items():\n",
    "        if pos==index:\n",
    "            print(word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73237c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
